{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Playing with submitting an average of high scoring kernels, as it seems\n",
    "# everyone else is doing. Weights were determined by guessing based on\n",
    "# their relative public leaderboard scores.\n",
    "#\n",
    "# This probably overfits, and proper work would involve running all these\n",
    "# kernels with CV and determining the proper weights on the OOF predictions.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "gru = pd.read_csv('../input/average_ensemble/pool_gru.csv') # PL score 0.9829\n",
    "lstm_nb_svm = pd.read_csv('../input/average_ensemble/lstm_nbsvm.csv') # 0.9811\n",
    "lr = pd.read_csv('../input/average_ensemble/lr.csv') # 0.9788\n",
    "lgb = pd.read_csv('../input/average_ensemble/lgb.csv') # 0.9785"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling toxic... Please stand by.\n",
      "Scaling severe_toxic... Please stand by.\n",
      "Scaling obscene... Please stand by.\n",
      "Scaling threat... Please stand by.\n",
      "Scaling insult... Please stand by.\n",
      "Scaling identity_hate... Please stand by.\n"
     ]
    }
   ],
   "source": [
    "# Bojan suggests scaling with min-max to make sure that all the submissions have\n",
    "# orderings that can be compared. Since our metric is AUC, this is okay and may\n",
    "# improve performance.\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "labels = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "for label in labels:\n",
    "    print('Scaling {}... Please stand by.'.format(label))\n",
    "    lgb[label] = minmax_scale(lgb[label])\n",
    "    gru[label] = minmax_scale(gru[label])\n",
    "    lr[label] = minmax_scale(lr[label])\n",
    "    lstm_nb_svm[label] = minmax_scale(lstm_nb_svm[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "[[1.         0.90111066 0.95377901 0.94273615]\n",
      " [0.90111066 1.         0.90236963 0.94926809]\n",
      " [0.95377901 0.90236963 1.         0.95823705]\n",
      " [0.94273615 0.94926809 0.95823705 1.        ]]\n",
      "severe_toxic\n",
      "[[1.         0.78884913 0.86371851 0.8186413 ]\n",
      " [0.78884913 1.         0.82051887 0.85339415]\n",
      " [0.86371851 0.82051887 1.         0.88252021]\n",
      " [0.8186413  0.85339415 0.88252021 1.        ]]\n",
      "obscene\n",
      "[[1.         0.93439385 0.94986687 0.94607069]\n",
      " [0.93439385 1.         0.92729218 0.96100403]\n",
      " [0.94986687 0.92729218 1.         0.955631  ]\n",
      " [0.94607069 0.96100403 0.955631   1.        ]]\n",
      "threat\n",
      "[[1.         0.75896158 0.83580206 0.79585943]\n",
      " [0.75896158 1.         0.79996174 0.78330735]\n",
      " [0.83580206 0.79996174 1.         0.84338327]\n",
      " [0.79585943 0.78330735 0.84338327 1.        ]]\n",
      "insult\n",
      "[[1.         0.89161567 0.92276276 0.90977553]\n",
      " [0.89161567 1.         0.88996881 0.93182386]\n",
      " [0.92276276 0.88996881 1.         0.93925792]\n",
      " [0.90977553 0.93182386 0.93925792 1.        ]]\n",
      "identity_hate\n",
      "[[1.         0.8159686  0.86413218 0.82264192]\n",
      " [0.8159686  1.         0.8130817  0.87086712]\n",
      " [0.86413218 0.8130817  1.         0.88949582]\n",
      " [0.82264192 0.87086712 0.88949582 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# The value of an ensemble is (a) the individual scores of the models and\n",
    "# (b) their correlation with one another. We want multiple individually high\n",
    "# scoring models that all have low correlations. Based on this analysis, it\n",
    "# looks like these kernels have relatively low correlations and will blend to a\n",
    "# much higher score.\n",
    "for label in labels:\n",
    "    print(label)\n",
    "    print(np.corrcoef([lgb[label], gru[label], lr[label], lstm_nb_svm[label]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['id'] = lgb['id']\n",
    "submission['toxic'] = lgb['toxic'] * 0.15 + gru['toxic'] * 0.4 + lr['toxic'] * 0.15 + lstm_nb_svm['toxic'] * 0.3\n",
    "submission['severe_toxic'] = lgb['severe_toxic'] * 0.15 + gru['severe_toxic'] * 0.4 + lr['severe_toxic'] * 0.15 + lstm_nb_svm['severe_toxic'] * 0.3\n",
    "submission['obscene'] = lgb['obscene'] * 0.15 + gru['obscene'] * 0.4 + lr['obscene'] * 0.15 + lstm_nb_svm['obscene'] * 0.3\n",
    "submission['threat'] = lgb['threat'] * 0.15 + gru['threat'] * 0.4 + lr['threat'] * 0.15 + lstm_nb_svm['threat'] * 0.3\n",
    "submission['insult'] = lgb['insult'] * 0.15 + gru['insult'] * 0.4 + lr['insult'] * 0.15 + lstm_nb_svm['insult'] * 0.3\n",
    "submission['identity_hate'] = lgb['identity_hate'] * 0.15 + gru['identity_hate'] * 0.4 + lr['identity_hate'] * 0.15 + lstm_nb_svm['identity_hate'] * 0.3\n",
    "submission.to_csv('../output/average_ensemble_0228.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
