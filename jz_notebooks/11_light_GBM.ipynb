{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The goal of this kernel is to demonstrate that LightGBM can have predictive\n",
    "# performance in line with that of a logistic regression. The theory is that\n",
    "# labeling is being driven by a few keywords that can be picked up by trees.\n",
    "#\n",
    "# With some careful tuning, patience with runtimes, and additional feature\n",
    "# engineering, this kernel can be tuned to slightly exceed the best\n",
    "# logistic regression. Best of all, the two approaches (LR and LGB) blend\n",
    "# well together.\n",
    "#\n",
    "# Hopefully, with some work, this could be a good addition to your ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded\n"
     ]
    }
   ],
   "source": [
    "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "train = pd.read_csv('../input/train.csv').fillna(' ')\n",
    "test = pd.read_csv('../input/test.csv').fillna(' ')\n",
    "print('Loaded')\n",
    "\n",
    "train_text = train['comment_text']\n",
    "test_text = test['comment_text']\n",
    "all_text = pd.concat([train_text, test_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word TFIDF 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wszjz\\AppData\\Local\\conda\\conda\\envs\\tfgpu\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word TFIDF 2/3\n",
      "Word TFIDF 3/3\n"
     ]
    }
   ],
   "source": [
    "word_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    ngram_range=(1, 2),\n",
    "    max_features=50000)\n",
    "word_vectorizer.fit(all_text)\n",
    "print('Word TFIDF 1/3')\n",
    "train_word_features = word_vectorizer.transform(train_text)\n",
    "print('Word TFIDF 2/3')\n",
    "test_word_features = word_vectorizer.transform(test_text)\n",
    "print('Word TFIDF 3/3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Char TFIDF 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wszjz\\AppData\\Local\\conda\\conda\\envs\\tfgpu\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Char TFIDF 2/3\n",
      "Char TFIDF 3/3\n"
     ]
    }
   ],
   "source": [
    "char_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='char',\n",
    "    stop_words='english',\n",
    "    ngram_range=(2, 6),\n",
    "    max_features=50000)\n",
    "char_vectorizer.fit(all_text)\n",
    "print('Char TFIDF 1/3')\n",
    "train_char_features = char_vectorizer.transform(train_text)\n",
    "print('Char TFIDF 2/3')\n",
    "test_char_features = char_vectorizer.transform(test_text)\n",
    "print('Char TFIDF 3/3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HStack 1/2\n",
      "HStack 2/2\n"
     ]
    }
   ],
   "source": [
    "train_features = hstack([train_char_features, train_word_features])\n",
    "print('HStack 1/2')\n",
    "test_features = hstack([test_char_features, test_word_features])\n",
    "print('HStack 2/2')\n",
    "\n",
    "submission = pd.DataFrame.from_dict({'id': test['id']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.drop('comment_text', axis=1, inplace=True)\n",
    "del test\n",
    "del train_text\n",
    "del test_text\n",
    "del all_text\n",
    "del train_char_features\n",
    "del test_char_features\n",
    "del train_word_features\n",
    "del test_word_features\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "(159571, 100000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wszjz\\AppData\\Local\\conda\\conda\\envs\\tfgpu\\lib\\site-packages\\sklearn\\utils\\__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 24954)\n",
      "[10]\ttraining's auc: 0.93934\tvalid_1's auc: 0.926078\n",
      "[20]\ttraining's auc: 0.961744\tvalid_1's auc: 0.944641\n",
      "[30]\ttraining's auc: 0.973841\tvalid_1's auc: 0.956544\n",
      "[40]\ttraining's auc: 0.980219\tvalid_1's auc: 0.962575\n",
      "[50]\ttraining's auc: 0.983948\tvalid_1's auc: 0.965518\n",
      "[60]\ttraining's auc: 0.98671\tvalid_1's auc: 0.96846\n",
      "[70]\ttraining's auc: 0.988697\tvalid_1's auc: 0.969916\n",
      "[80]\ttraining's auc: 0.990201\tvalid_1's auc: 0.970408\n",
      "[90]\ttraining's auc: 0.99154\tvalid_1's auc: 0.970967\n",
      "[100]\ttraining's auc: 0.992609\tvalid_1's auc: 0.971041\n",
      "[110]\ttraining's auc: 0.99352\tvalid_1's auc: 0.971244\n",
      "[120]\ttraining's auc: 0.994341\tvalid_1's auc: 0.971235\n",
      "[130]\ttraining's auc: 0.994972\tvalid_1's auc: 0.971586\n",
      "[140]\ttraining's auc: 0.995591\tvalid_1's auc: 0.971679\n",
      "severe_toxic\n",
      "(159571, 100000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wszjz\\AppData\\Local\\conda\\conda\\envs\\tfgpu\\lib\\site-packages\\sklearn\\utils\\__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 6352)\n",
      "[10]\ttraining's auc: 0.972672\tvalid_1's auc: 0.96486\n",
      "[20]\ttraining's auc: 0.990887\tvalid_1's auc: 0.985212\n",
      "[30]\ttraining's auc: 0.994264\tvalid_1's auc: 0.985903\n",
      "[40]\ttraining's auc: 0.996728\tvalid_1's auc: 0.984439\n",
      "[50]\ttraining's auc: 0.997903\tvalid_1's auc: 0.983392\n",
      "obscene\n",
      "(159571, 100000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wszjz\\AppData\\Local\\conda\\conda\\envs\\tfgpu\\lib\\site-packages\\sklearn\\utils\\__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 13720)\n",
      "[10]\ttraining's auc: 0.980456\tvalid_1's auc: 0.981755\n",
      "[20]\ttraining's auc: 0.990982\tvalid_1's auc: 0.989378\n",
      "[30]\ttraining's auc: 0.994175\tvalid_1's auc: 0.991522\n",
      "[40]\ttraining's auc: 0.995721\tvalid_1's auc: 0.992936\n",
      "[50]\ttraining's auc: 0.996787\tvalid_1's auc: 0.99359\n",
      "[60]\ttraining's auc: 0.997499\tvalid_1's auc: 0.993388\n",
      "[70]\ttraining's auc: 0.998026\tvalid_1's auc: 0.993501\n",
      "[80]\ttraining's auc: 0.998412\tvalid_1's auc: 0.993769\n",
      "threat\n",
      "(159571, 100000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wszjz\\AppData\\Local\\conda\\conda\\envs\\tfgpu\\lib\\site-packages\\sklearn\\utils\\__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 3286)\n",
      "[10]\ttraining's auc: 0.954414\tvalid_1's auc: 0.83758\n",
      "[20]\ttraining's auc: 0.994329\tvalid_1's auc: 0.935639\n",
      "[30]\ttraining's auc: 0.998239\tvalid_1's auc: 0.960796\n",
      "[40]\ttraining's auc: 0.999624\tvalid_1's auc: 0.980023\n",
      "[50]\ttraining's auc: 0.999916\tvalid_1's auc: 0.977887\n",
      "[60]\ttraining's auc: 0.999981\tvalid_1's auc: 0.978615\n",
      "[70]\ttraining's auc: 0.999996\tvalid_1's auc: 0.973916\n",
      "[80]\ttraining's auc: 0.999999\tvalid_1's auc: 0.981116\n",
      "insult\n",
      "(159571, 100000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wszjz\\AppData\\Local\\conda\\conda\\envs\\tfgpu\\lib\\site-packages\\sklearn\\utils\\__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 16821)\n",
      "[10]\ttraining's auc: 0.955145\tvalid_1's auc: 0.946272\n",
      "[20]\ttraining's auc: 0.975689\tvalid_1's auc: 0.967746\n",
      "[30]\ttraining's auc: 0.984063\tvalid_1's auc: 0.97636\n",
      "[40]\ttraining's auc: 0.988461\tvalid_1's auc: 0.978564\n",
      "[50]\ttraining's auc: 0.99099\tvalid_1's auc: 0.979352\n",
      "[60]\ttraining's auc: 0.992611\tvalid_1's auc: 0.980395\n",
      "[70]\ttraining's auc: 0.993882\tvalid_1's auc: 0.980878\n",
      "identity_hate\n",
      "(159571, 100000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wszjz\\AppData\\Local\\conda\\conda\\envs\\tfgpu\\lib\\site-packages\\sklearn\\utils\\__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 6929)\n",
      "[10]\ttraining's auc: 0.934593\tvalid_1's auc: 0.877853\n",
      "[20]\ttraining's auc: 0.979445\tvalid_1's auc: 0.936626\n",
      "[30]\ttraining's auc: 0.993146\tvalid_1's auc: 0.972944\n",
      "[40]\ttraining's auc: 0.996837\tvalid_1's auc: 0.978698\n",
      "[50]\ttraining's auc: 0.998357\tvalid_1's auc: 0.979557\n",
      "[60]\ttraining's auc: 0.999036\tvalid_1's auc: 0.98002\n",
      "[70]\ttraining's auc: 0.999456\tvalid_1's auc: 0.980195\n",
      "[80]\ttraining's auc: 0.999689\tvalid_1's auc: 0.979861\n"
     ]
    }
   ],
   "source": [
    "for class_name in class_names:\n",
    "    print(class_name)\n",
    "    train_target = train[class_name]\n",
    "    model = LogisticRegression(solver='sag')\n",
    "    sfm = SelectFromModel(model, threshold=0.2)\n",
    "    print(train_features.shape)\n",
    "    train_sparse_matrix = sfm.fit_transform(train_features, train_target)\n",
    "    print(train_sparse_matrix.shape)\n",
    "    train_sparse_matrix, valid_sparse_matrix, y_train, y_valid = train_test_split(train_sparse_matrix, train_target, test_size=0.05, random_state=144)\n",
    "    test_sparse_matrix = sfm.transform(test_features)\n",
    "    d_train = lgb.Dataset(train_sparse_matrix, label=y_train)\n",
    "    d_valid = lgb.Dataset(valid_sparse_matrix, label=y_valid)\n",
    "    watchlist = [d_train, d_valid]\n",
    "    params = {'learning_rate': 0.2,\n",
    "              'application': 'binary',\n",
    "              'num_leaves': 31,\n",
    "              'verbosity': -1,\n",
    "              'metric': 'auc',\n",
    "              'data_random_seed': 2,\n",
    "              'bagging_fraction': 0.8,\n",
    "              'feature_fraction': 0.6,\n",
    "              'nthread': 4,\n",
    "              'lambda_l1': 1,\n",
    "              'lambda_l2': 1}\n",
    "    rounds_lookup = {'toxic': 140,\n",
    "                 'severe_toxic': 50,\n",
    "                 'obscene': 80,\n",
    "                 'threat': 80,\n",
    "                 'insult': 70,\n",
    "                 'identity_hate': 80}\n",
    "    model = lgb.train(params,\n",
    "                      train_set=d_train,\n",
    "                      num_boost_round=rounds_lookup[class_name],\n",
    "                      valid_sets=watchlist,\n",
    "                      verbose_eval=10)\n",
    "    submission[class_name] = model.predict(test_sparse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('lgb_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
